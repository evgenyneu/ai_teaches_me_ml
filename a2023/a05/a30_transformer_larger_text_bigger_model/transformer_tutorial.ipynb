{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to play with model hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import torch\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data set\n",
    "# --------------------\n",
    "\n",
    "def read_text(path):\n",
    "  with open(path, 'r') as f:\n",
    "    return f.read()\n",
    "  \n",
    "text_paths = [\n",
    "  \"../a06_RNN_language_model/animal_farm.txt\",\n",
    "  \"../a22_transformer_larger_text/books/alice-s-adventures-in-wonderland.txt\",\n",
    "  \"../a22_transformer_larger_text/books/a_room_with_a_view_forster.txt\",\n",
    "  \"../a22_transformer_larger_text/books/the_enchanted_april_elizabeth_von_arnim.txt\"\n",
    "]\n",
    "\n",
    "texts = [read_text(path) for path in text_paths]\n",
    "text_train = ' '.join(texts)\n",
    "\n",
    "print(\"Text size: \", len(text_train))\n",
    "\n",
    "# Create list of unique characters\n",
    "vocab = sorted(list(set(text_train)))\n",
    "\n",
    "# Create dictionaries that map characters to integers and vice versa\n",
    "char_to_int = {c: i for i, c in enumerate(vocab)}\n",
    "int_to_char = {i: c for i, c in enumerate(vocab)}\n",
    "\n",
    "# Convert text to integers\n",
    "train_data = torch.tensor([char_to_int[c] for c in text_train])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
    "    \"\"\"Divides the data into ``bsz`` separate sequences, removing extra elements\n",
    "    that wouldn't cleanly fit.\n",
    "\n",
    "    Arguments:\n",
    "        data: Tensor, shape ``[N]``\n",
    "        bsz: int, batch size\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape ``[N // bsz, bsz]``\n",
    "    \"\"\"\n",
    "    seq_len = data.size(0) // bsz\n",
    "    data = data[:seq_len * bsz]\n",
    "    data = data.view(bsz, seq_len).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "batch_size = 50\n",
    "train_data = batchify(train_data, batch_size)  # shape ``[seq_len, batch_size]``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            src: Tensor, shape ``[seq_len, batch_size]``\n",
    "            src_mask: Tensor, shape ``[seq_len, seq_len]``\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape ``[seq_len, batch_size, ntoken]``\n",
    "        \"\"\"\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
    "    \"\"\"Generates an upper-triangular matrix of ``-inf``, with zeros on ``diag``.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
    "  \n",
    "  \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 30\n",
    "\n",
    "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
    "  \"\"\"\n",
    "  Args:\n",
    "      source: Tensor, sha2[seq_len * batch_size]``\n",
    "  \"\"\"\n",
    "  seq_len = min(bptt, len(source) - 1 - i)\n",
    "  data = source[i:i+seq_len]\n",
    "  target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "  return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(vocab)  # size of vocabulary\n",
    "emsize = 200  # embedding dimension\n",
    "d_hid = 400  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "nlayers = 8  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "nhead = 8  # number of heads in ``nn.MultiheadAttention``\n",
    "dropout = 0.2  # dropout probability\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad) # total number of trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001  # learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def train(model: nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        optimizer.zero_grad()\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        seq_len = data.size(0)\n",
    "        if seq_len != bptt:  # only on last batch\n",
    "            src_mask = src_mask[:seq_len, :seq_len]\n",
    "        output = model(data, src_mask)\n",
    "        loss = criterion(output.view(-1, ntokens), targets) \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    return total_loss / (batch + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "start_time = time.time()\n",
    "\n",
    "with TemporaryDirectory() as tempdir:\n",
    "  for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train_loss = train(model)\n",
    "    print(f'Epoch {epoch:3d}: {train_loss:5.4f}')\n",
    "\n",
    "\n",
    "print(f\"Training time: {round(time.time() - start_time)} seconds\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Epoch   1: 2.1162\n",
    "Epoch   2: 1.7529\n",
    "Epoch   3: 1.6641\n",
    "Epoch   4: 1.6140\n",
    "Epoch   5: 1.5809\n",
    "Epoch   6: 1.5563\n",
    "Epoch   7: 1.5358\n",
    "Epoch   8: 1.5219\n",
    "Epoch   9: 1.5088\n",
    "Epoch  10: 1.4986\n",
    "Epoch  11: 1.4891\n",
    "Epoch  12: 1.4808\n",
    "Epoch  13: 1.4737\n",
    "Epoch  14: 1.4686\n",
    "Epoch  15: 1.4626\n",
    "Epoch  16: 1.4574\n",
    "Epoch  17: 1.4527\n",
    "Epoch  18: 1.4483\n",
    "Epoch  19: 1.4441\n",
    "Epoch  20: 1.4406\n",
    "Epoch  21: 1.4366\n",
    "Epoch  22: 1.4334\n",
    "Epoch  23: 1.4306\n",
    "Epoch  24: 1.4278\n",
    "Epoch  25: 1.4235\n",
    "Epoch  26: 1.4225\n",
    "Epoch  27: 1.4200\n",
    "Epoch  28: 1.4177\n",
    "Epoch  29: 1.4151\n",
    "Epoch  30: 1.4126\n",
    "Epoch  31: 1.4115\n",
    "Epoch  32: 1.4102\n",
    "Epoch  33: 1.4069\n",
    "Epoch  34: 1.4059\n",
    "Epoch  35: 1.4037\n",
    "Epoch  36: 1.4019\n",
    "Epoch  37: 1.4001\n",
    "Epoch  38: 1.3996\n",
    "Epoch  39: 1.3981\n",
    "Epoch  40: 1.3970\n",
    "Epoch  41: 1.3961\n",
    "Epoch  42: 1.3942\n",
    "Epoch  43: 1.3924\n",
    "Epoch  44: 1.3921\n",
    "Epoch  45: 1.3913\n",
    "Epoch  46: 1.3891\n",
    "Epoch  47: 1.3891\n",
    "Epoch  48: 1.3881\n",
    "Epoch  49: 1.3867\n",
    "Epoch  50: 1.3856\n",
    "Training time: 360 seconds\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(model, initial_text, n_elements, temperature=1.0):\n",
    "  model.eval()  # Set the model to evaluation mode\n",
    "  \n",
    "  initial_sequence = [char_to_int[c] for c in initial_text]\n",
    "  generated_sequence = initial_sequence\n",
    "  src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "  \n",
    "  # Use torch.no_grad() to prevent gradient calculations during text generation\n",
    "  with torch.no_grad():\n",
    "    # Generate new elements\n",
    "    for _ in range(n_elements):\n",
    "      # Convert the input_sequence to a tensor and add batch dimension\n",
    "      input_tensor = torch.tensor(generated_sequence[-bptt:]).unsqueeze(1).to(device)\n",
    "      seq_len = input_tensor.size(0)\n",
    "      \n",
    "      if seq_len != bptt:\n",
    "        src_mask = src_mask[:seq_len, :seq_len]\n",
    "    \n",
    "      # Evaluate the model\n",
    "      output = model(input_tensor, src_mask)\n",
    "      \n",
    "                        \n",
    "      # Apply temperature scaling to the output logits to control the randomness of the generated text\n",
    "      output = output[-1, 0, :] / temperature\n",
    "            \n",
    "      # Convert the output logits into probabilities using softmax\n",
    "      probabilities = torch.softmax(output, dim=-1)\n",
    "          \n",
    "      # Sample the next element using the probabilities\n",
    "      next_element = torch.multinomial(probabilities, num_samples=1).item()\n",
    "      \n",
    "      # Append the element\n",
    "      generated_sequence += [next_element]\n",
    "\n",
    "  generated_text = [int_to_char[c] for c in generated_sequence]\n",
    "  return ''.join(generated_text)\n",
    "\n",
    "generated = generate_sequence(model, \"We are not like that\", 300, 0.8)\n",
    "print(generated)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample output\n",
    "\n",
    "We are not like that; and think they had personed again them to greet of the first London weeks might learn before the house she was never assument pieces and the other train from an opportunity, and the looked at the least thing with a solemnly cup of other way and got up it off on and rent down with the moment the fr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
