{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing transformer from tutorial https://pytorch.org/tutorials/beginner/transformer_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            src: Tensor, shape ``[seq_len, batch_size]``\n",
    "            src_mask: Tensor, shape ``[seq_len, seq_len]``\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape ``[seq_len, batch_size, ntoken]``\n",
    "        \"\"\"\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
    "    \"\"\"Generates an upper-triangular matrix of ``-inf``, with zeros on ``diag``.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
    "  \n",
    "  \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "train_iter = WikiText2(split='train')\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
    "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
    "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
    "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "# ``train_iter`` was \"consumed\" by the process of building the vocab,\n",
    "# so we have to create it again\n",
    "train_iter, val_iter, test_iter = WikiText2()\n",
    "train_data = data_process(train_iter)\n",
    "val_data = data_process(val_iter)\n",
    "test_data = data_process(test_iter)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
    "    \"\"\"Divides the data into ``bsz`` separate sequences, removing extra elements\n",
    "    that wouldn't cleanly fit.\n",
    "\n",
    "    Arguments:\n",
    "        data: Tensor, shape ``[N]``\n",
    "        bsz: int, batch size\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape ``[N // bsz, bsz]``\n",
    "    \"\"\"\n",
    "    seq_len = data.size(0) // bsz\n",
    "    data = data[:seq_len * bsz]\n",
    "    data = data.view(bsz, seq_len).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "batch_size = 20\n",
    "eval_batch_size = 10\n",
    "train_data = batchify(train_data, batch_size)  # shape ``[seq_len, batch_size]``\n",
    "val_data = batchify(val_data, eval_batch_size)\n",
    "test_data = batchify(test_data, eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 35\n",
    "\n",
    "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        source: Tensor, shape ``[full_seq_len, batch_size]``\n",
    "        i: int\n",
    "\n",
    "    Returns:\n",
    "        tuple (data, target), where data has shape ``[seq_len, batch_size]`` and\n",
    "        target has shape ``[seq_len * batch_size]``\n",
    "    \"\"\"\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(vocab)  # size of vocabulary\n",
    "emsize = 200  # embedding dimension\n",
    "d_hid = 200  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "nlayers = 2  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "nhead = 2  # number of heads in ``nn.MultiheadAttention``\n",
    "dropout = 0.2  # dropout probability\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "def train(model: nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.\n",
    "    log_interval = 200\n",
    "    start_time = time.time()\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "\n",
    "    num_batches = len(train_data) // bptt\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        seq_len = data.size(0)\n",
    "        if seq_len != bptt:  # only on last batch\n",
    "            src_mask = src_mask[:seq_len, :seq_len]\n",
    "        output = model(data, src_mask)\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
    "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(eval_data, i)\n",
    "            seq_len = data.size(0)\n",
    "            if seq_len != bptt:\n",
    "                src_mask = src_mask[:seq_len, :seq_len]\n",
    "            output = model(data, src_mask)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += seq_len * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(eval_data) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   200/ 2928 batches | lr 5.00 | ms/batch  7.55 | loss  8.13 | ppl  3396.63\n",
      "| epoch   1 |   400/ 2928 batches | lr 5.00 | ms/batch  5.27 | loss  6.88 | ppl   969.26\n",
      "| epoch   1 |   600/ 2928 batches | lr 5.00 | ms/batch  5.25 | loss  6.42 | ppl   613.89\n",
      "| epoch   1 |   800/ 2928 batches | lr 5.00 | ms/batch  5.24 | loss  6.30 | ppl   543.45\n",
      "| epoch   1 |  1000/ 2928 batches | lr 5.00 | ms/batch  5.23 | loss  6.18 | ppl   482.97\n",
      "| epoch   1 |  1200/ 2928 batches | lr 5.00 | ms/batch  5.30 | loss  6.15 | ppl   469.44\n",
      "| epoch   1 |  1400/ 2928 batches | lr 5.00 | ms/batch  5.31 | loss  6.11 | ppl   448.24\n",
      "| epoch   1 |  1600/ 2928 batches | lr 5.00 | ms/batch  5.53 | loss  6.10 | ppl   444.61\n",
      "| epoch   1 |  1800/ 2928 batches | lr 5.00 | ms/batch  5.27 | loss  6.02 | ppl   410.30\n",
      "| epoch   1 |  2000/ 2928 batches | lr 5.00 | ms/batch  5.23 | loss  6.01 | ppl   406.25\n",
      "| epoch   1 |  2200/ 2928 batches | lr 5.00 | ms/batch  5.28 | loss  5.90 | ppl   363.42\n",
      "| epoch   1 |  2400/ 2928 batches | lr 5.00 | ms/batch  5.24 | loss  5.96 | ppl   389.22\n",
      "| epoch   1 |  2600/ 2928 batches | lr 5.00 | ms/batch  5.24 | loss  5.95 | ppl   382.74\n",
      "| epoch   1 |  2800/ 2928 batches | lr 5.00 | ms/batch  5.23 | loss  5.87 | ppl   356.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 16.55s | valid loss  5.78 | valid ppl   322.59\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   200/ 2928 batches | lr 4.75 | ms/batch  5.27 | loss  5.86 | ppl   350.28\n",
      "| epoch   2 |   400/ 2928 batches | lr 4.75 | ms/batch  5.23 | loss  5.85 | ppl   347.55\n",
      "| epoch   2 |   600/ 2928 batches | lr 4.75 | ms/batch  5.26 | loss  5.67 | ppl   289.32\n",
      "| epoch   2 |   800/ 2928 batches | lr 4.75 | ms/batch  5.38 | loss  5.70 | ppl   298.19\n",
      "| epoch   2 |  1000/ 2928 batches | lr 4.75 | ms/batch  5.36 | loss  5.64 | ppl   282.21\n",
      "| epoch   2 |  1200/ 2928 batches | lr 4.75 | ms/batch  5.23 | loss  5.67 | ppl   290.86\n",
      "| epoch   2 |  1400/ 2928 batches | lr 4.75 | ms/batch  5.29 | loss  5.68 | ppl   292.59\n",
      "| epoch   2 |  1600/ 2928 batches | lr 4.75 | ms/batch  5.24 | loss  5.70 | ppl   297.93\n",
      "| epoch   2 |  1800/ 2928 batches | lr 4.75 | ms/batch  5.23 | loss  5.65 | ppl   283.42\n",
      "| epoch   2 |  2000/ 2928 batches | lr 4.75 | ms/batch  5.24 | loss  5.66 | ppl   286.11\n",
      "| epoch   2 |  2200/ 2928 batches | lr 4.75 | ms/batch  5.25 | loss  5.54 | ppl   254.79\n",
      "| epoch   2 |  2400/ 2928 batches | lr 4.75 | ms/batch  5.27 | loss  5.64 | ppl   280.52\n",
      "| epoch   2 |  2600/ 2928 batches | lr 4.75 | ms/batch  5.27 | loss  5.64 | ppl   280.88\n",
      "| epoch   2 |  2800/ 2928 batches | lr 4.75 | ms/batch  5.25 | loss  5.57 | ppl   262.43\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 16.08s | valid loss  5.62 | valid ppl   274.77\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |   200/ 2928 batches | lr 4.51 | ms/batch  5.31 | loss  5.59 | ppl   267.17\n",
      "| epoch   3 |   400/ 2928 batches | lr 4.51 | ms/batch  5.27 | loss  5.61 | ppl   272.36\n",
      "| epoch   3 |   600/ 2928 batches | lr 4.51 | ms/batch  5.25 | loss  5.41 | ppl   223.20\n",
      "| epoch   3 |   800/ 2928 batches | lr 4.51 | ms/batch  5.25 | loss  5.46 | ppl   235.62\n",
      "| epoch   3 |  1000/ 2928 batches | lr 4.51 | ms/batch  5.25 | loss  5.42 | ppl   225.70\n",
      "| epoch   3 |  1200/ 2928 batches | lr 4.51 | ms/batch  5.26 | loss  5.47 | ppl   236.67\n",
      "| epoch   3 |  1400/ 2928 batches | lr 4.51 | ms/batch  5.25 | loss  5.49 | ppl   241.10\n",
      "| epoch   3 |  1600/ 2928 batches | lr 4.51 | ms/batch  5.19 | loss  5.52 | ppl   248.41\n",
      "| epoch   3 |  1800/ 2928 batches | lr 4.51 | ms/batch  5.21 | loss  5.45 | ppl   232.61\n",
      "| epoch   3 |  2000/ 2928 batches | lr 4.51 | ms/batch  5.32 | loss  5.47 | ppl   238.24\n",
      "| epoch   3 |  2200/ 2928 batches | lr 4.51 | ms/batch  5.37 | loss  5.36 | ppl   212.27\n",
      "| epoch   3 |  2400/ 2928 batches | lr 4.51 | ms/batch  5.37 | loss  5.46 | ppl   234.39\n",
      "| epoch   3 |  2600/ 2928 batches | lr 4.51 | ms/batch  5.22 | loss  5.47 | ppl   236.54\n",
      "| epoch   3 |  2800/ 2928 batches | lr 4.51 | ms/batch  5.29 | loss  5.40 | ppl   221.65\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 16.09s | valid loss  5.57 | valid ppl   261.41\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "epochs = 3\n",
    "\n",
    "with TemporaryDirectory() as tempdir:\n",
    "    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(model)\n",
    "        val_loss = evaluate(model, val_data)\n",
    "        val_ppl = math.exp(val_loss)\n",
    "        elapsed = time.time() - epoch_start_time\n",
    "        print('-' * 89)\n",
    "        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
    "            f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
    "        print('-' * 89)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "        scheduler.step()\n",
    "    model.load_state_dict(torch.load(best_model_params_path)) # load best model states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss  5.47 | test ppl   238.25\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(model, test_data)\n",
    "test_ppl = math.exp(test_loss)\n",
    "print('=' * 89)\n",
    "print(f'| End of training | test loss {test_loss:5.2f} | '\n",
    "      f'test ppl {test_ppl:8.2f}')\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
